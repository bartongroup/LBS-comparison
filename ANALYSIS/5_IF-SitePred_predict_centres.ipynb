{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746a99c2-bf08-4917-95f6-137ee1ddc393",
   "metadata": {},
   "source": [
    "# Running IF-SitePred in Jupyter NB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b800f-cfa7-4db9-8015-61c0759454d8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4c994b-d3f5-46a5-8c05-23f3647bfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymol import cmd, stored\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "import pandas as pd\n",
    "import time \n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaea4c-3b86-4340-b4dc-71a30abeda46",
   "metadata": {},
   "source": [
    "## Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866efd0c-e025-476a-8ede-1edc1eb5cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(variable, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(variable, file)\n",
    "\n",
    "def read_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def write_chimerax_attr_file(data, attr_name, file_name, model_id='1', chain_id='A'):\n",
    "    with open(file_name, 'w') as file:\n",
    "        # Write the header\n",
    "        file.write(f\"attribute: {attr_name}\\n\")\n",
    "        file.write(\"match mode: any\\n\")\n",
    "        file.write(\"recipient: residues\\n\")\n",
    "        file.write(\"\\n\")  # Blank line for readability\n",
    "        \n",
    "        # Write each residue's attribute\n",
    "        for attr_value, res_nums in data.items():\n",
    "            for res_num in res_nums:\n",
    "                file.write(f\"\\t#{model_id}/{chain_id}:{res_num}\\t{str(attr_value + 1)}\\n\")\n",
    "\n",
    "def generate_distinct_colors_hex(n):\n",
    "    colors_hex = []\n",
    "    for i in range(n):\n",
    "        # Divide the hue space evenly\n",
    "        hue = i / n\n",
    "        # Set saturation and lightness to 0.5 for vibrant colors\n",
    "        saturation, lightness = 0.5, 0.5\n",
    "        # Convert HSL to RGB\n",
    "        rgb = colorsys.hls_to_rgb(hue, lightness, saturation)\n",
    "        # Convert to hex, scaling RGB values to 0-255\n",
    "        hex_color = '#' + ''.join(f'{int(val * 255):02x}' for val in rgb)\n",
    "        colors_hex.append(hex_color)\n",
    "    return colors_hex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94cff7-51d4-4f3a-a17b-14dac4a7e885",
   "metadata": {},
   "source": [
    "## Predicting sites functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c21016-8427-498b-b547-431588ff6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_xyz(coords, target):\n",
    "    \"\"\"\n",
    "    writes point cloud of pseudoatoms boxed around protein into xyz file\n",
    "    \"\"\"\n",
    "    \n",
    "    min_coords = [np.min(coords[:,0])-10, np.min(coords[:,1])-10, np.min(coords[:,2])-10]\n",
    "    max_coords = [np.max(coords[:,0])+10, np.max(coords[:,1])+10, np.max(coords[:,2])+10]\n",
    "\n",
    "    [x, y, z] = [np.arange(min_coords[i], max_coords[i], 1.5) for i in range(3)]\n",
    "\n",
    "    with open(f'./results/xyz/xyz_{target}.xyz', 'w') as w:\n",
    "        w.write(f'{len(x)*len(y)*len(z)}\\npoint\\n')\n",
    "        for a in x:\n",
    "            for b in y:\n",
    "                for c in z:\n",
    "                    a_val = round(a, 3)\n",
    "                    b_val = round(b, 3)\n",
    "                    c_val = round(c, 3)\n",
    "                    w.write(f'PS {a_val:.3f} {b_val:.3f} {c_val:.3f}\\n')\n",
    "\n",
    "\n",
    "def write_repeats(coords):\n",
    "    with open('repeats.xyz', 'w') as w:\n",
    "        w.write(f'{len(coords)}\\npoint\\n')\n",
    "        for c in coords:\n",
    "            w.write(f'PS {c[0]:.3f} {c[1]:.3f} {c[2]:.3f}\\n')\n",
    "\n",
    "def write_coords(coords, filename):\n",
    "    with open(filename, 'w') as w:\n",
    "        w.write(f'{len(coords)}\\npoint\\n')\n",
    "        for c in coords:\n",
    "            w.write(f'PS {c[0]:.3f} {c[1]:.3f} {c[2]:.3f}\\n')\n",
    "\n",
    "\n",
    "def get_final_cloud(pdb, target, final_preds, chain):\n",
    "    \"\"\"\n",
    "    extracts points in point cloud that are close to protein residues that have been predicted to be druggable\n",
    "    \"\"\"\n",
    "    coords = np.array(cmd.get_coords('chA')) \n",
    "    write_xyz(coords, target)\n",
    "    assert os.path.exists(f'./results/xyz/xyz_{target}.xyz')\n",
    "    cmd.load(f'./results/xyz/xyz_{target}.xyz','cloud1')\n",
    "\n",
    "    cmd.extract('cloud3', 'cloud1 within 3 of chA')\n",
    "    cmd.extract('cloud_bubble', 'cloud1 within 6 of chA') # don't want these\n",
    "\n",
    "    for p in range(len(final_preds)):\n",
    "        cmd.select(f'sele_{final_preds[p]}', f'chA and resi {final_preds[p]}') \n",
    "        if cmd.count_atoms(f'cloud_bubble within 4.5 of sele_{final_preds[p]}') > 0:\n",
    "            cmd.create('cloud', f'cloud_bubble within 4.5 of sele_{final_preds[p]}')\n",
    "            cmd.delete(f'sele_{final_preds[p]}')\n",
    "            break\n",
    "    \n",
    "    for i in final_preds[p+1:]:\n",
    "        try:\n",
    "            cmd.select(f'sele_{i}', f'chA and resi {i}')\n",
    "            cmd.create(f'cloud1_{i}', f'cloud_bubble within 4.5 of sele_{i}')\n",
    "            if cmd.count_atoms(f'cloud1_{i}') > 0:\n",
    "                cmd.copy_to('cloud', f'cloud1_{i}')\n",
    "            cmd.delete(f'sele_{i}')\n",
    "        except:\n",
    "            raise\n",
    "\n",
    "\n",
    "    coords = cmd.get_coords('cloud')\n",
    "    coord_list = [','.join([str(n) for n in i]) for i in coords]\n",
    "    repeats = list(sorted([i for i in coord_list if coord_list.count(i) > 2]))\n",
    "    repeats = np.array([[float(x) for x in c.split(',')] for c in repeats])\n",
    "\n",
    "    return repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b3223-358f-4496-8ac4-458cbee74d8c",
   "metadata": {},
   "source": [
    "## Target selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0591ee87-b423-483c-965c-5aed76c09b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = './../../rep_chains'\n",
    "preds_dir = \"./results/IFSP_preds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d740a6-57cd-415f-929b-5a1863b35049",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_targets = read_from_pickle(r\"./results/PDB_rep_chains_files.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c3a012-f007-4959-b350-f66b90a3fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = read_from_pickle(\"./results/PDB_rep_chains_files_V2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ea41a1-84fe-4f49-b1d8-4f6b8a7478cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4037\n"
     ]
    }
   ],
   "source": [
    "N_targets = len(targets)\n",
    "print(N_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eafed1e4-061f-41a0-941f-e68d5896bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2128\n"
     ]
    }
   ],
   "source": [
    "new_targets = [target for target in targets if target not in OLD_targets]\n",
    "print(len(new_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac80907-fa1a-423b-8132-a49f46b82e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20467.125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(23391/8)*7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08bf49f-a31a-4e7c-9e1d-5545413d3a98",
   "metadata": {},
   "source": [
    "It is now 16:33 on 26/03/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d290e6a-6a22-4610-b457-e4c0b856887f",
   "metadata": {},
   "source": [
    "## Running IF-SitePred on Human LIGYSIS representative ligand-binding chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6401b00-765a-4182-b71f-788118f8f482",
   "metadata": {},
   "source": [
    "Started at 23:14 ON 04/04/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7217e6-4cdf-4dfd-b60f-5d4151c807db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eb9e4b4-1e2d-43e8-9cae-f1b3fb0d6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_sites = read_from_pickle(\"./results/IFSP_no_sites_half.pkl\")\n",
    "sites_per_prot = read_from_pickle(\"./results/IFSP_sites_per_prot_half.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb4006a5-cc22-4a39-b121-607dff338c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_sites = list(sites_per_prot.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99bfdc06-bdf9-4ee5-acb2-9001afef3984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "1128\n"
     ]
    }
   ],
   "source": [
    "print(len(no_sites))\n",
    "print(len(yes_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "274df517-95b0-4e27-98eb-77d09eab46c9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "10 sites found for 6cph_D\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i, target in enumerate(new_targets):\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "\n",
    "    if target_id in no_sites:\n",
    "        continue\n",
    "\n",
    "    elif target_id in yes_sites:\n",
    "        continue\n",
    "\n",
    "    target_id = target.split(\".\")[0]\n",
    "    target_path = os.path.join(target_dir, target)\n",
    "    \n",
    "    prediction_dir = os.path.join(preds_dir, target_id)\n",
    "    \n",
    "    binding_ress_path = os.path.join(prediction_dir, f'{target_id}_binding_ress.pkl')\n",
    "    \n",
    "    if not os.path.isfile(binding_ress_path):\n",
    "        continue\n",
    "\n",
    "    binding_ress = read_from_pickle(binding_ress_path)\n",
    "    chain = list(binding_ress.keys())[0]\n",
    "    preds = list(binding_ress.values())[0]\n",
    "\n",
    "    if preds == []:\n",
    "        print(\"No binding residues for {}\".format(target_id))\n",
    "        no_sites.append(target_id)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        cmd.reinitialize()\n",
    "        \n",
    "        cmd.load(target_path, 'complex')\n",
    "        \n",
    "        cmd.extract('hets', 'complex and HETATM')\n",
    "        \n",
    "        cmd.delete('hets')\n",
    "        \n",
    "        cmd.extract('chA', f'complex and chain {chain}')\n",
    "    \n",
    "        int_preds = [int(pred) for pred in preds]\n",
    "        \n",
    "        final_coords = get_final_cloud(target_path, target_id, preds, chain)\n",
    "    \n",
    "        if final_coords.size == 0:\n",
    "            print(\"No sites were found for {}\".format(target_id))\n",
    "            no_sites.append(target_id)\n",
    "        else:\n",
    "    \n",
    "            # cluster coordinates (that have been repeated by different residues) with a maximum distance threshold of 1.5A\n",
    "            clustering = DBSCAN(eps=1.7, min_samples=2).fit(final_coords)\n",
    "        \n",
    "            # get size of each cluster for ranking\n",
    "            site_counts = {}\n",
    "            for site in set(clustering.labels_):\n",
    "                if int(site) != -1:\n",
    "                    site_counts[site] = list(clustering.labels_).count(site)\n",
    "        \n",
    "            print('{} sites found for {}'.format(str(len(site_counts)), target_id))\n",
    "            sites_per_prot[target_id] = site_counts\n",
    "            \n",
    "            for site_rank in range(len(site_counts)):\n",
    "        \n",
    "                biggest = max(site_counts, key=site_counts.get)\n",
    "        \n",
    "                # get coordinates of points in selected site, and calculate the centre by taking the mean of all points in the site\n",
    "                main_site = np.array([final_coords[i] for i in range(len(final_coords)) if clustering.labels_[i] == biggest])\n",
    "                \n",
    "                write_coords(main_site, f'./results/IFSP_preds/{target_id}/site_rank_{site_rank+1}.xyz')\n",
    "                \n",
    "                centre = np.array([np.mean(main_site[:,0]), np.mean(main_site[:,1]), np.mean(main_site[:,2])])\n",
    "        \n",
    "                with open(f'./results/IFSP_preds/{target_id}/centre_rank_{site_rank+1}.xyz', 'w') as w:\n",
    "                    w.write(f'1\\npoint\\n')\n",
    "                    w.write(f'PS {centre[0]:.3f} {centre[1]:.3f} {centre[2]:.3f}\\n')\n",
    "        \n",
    "                del site_counts[biggest]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"ERROR with {}\".format(target_id))\n",
    "        errors.append(target)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a73c0c99-c800-472c-8858-cca14b8d7295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4181e80-9849-43a7-b2f8-67a33d9e52c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ee59f33-5c68-46ef-9f7c-f8b75606b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(no_sites, \"./results/IFSP_no_site_accs_V2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c04f5d-2646-4175-b496-6fc6eb31c031",
   "metadata": {},
   "source": [
    "## ChimeraX colouring commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a063420-942d-4f43-b299-1e1f7c8c36f0",
   "metadata": {},
   "source": [
    "To colour by ligandability score:\n",
    "    \n",
    "    color byattribute r:ligandability #!1 target scab palette 0,white:0.5,#febe55:1,#de2d26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa985424-c05b-455c-b912-17375bb42cd4",
   "metadata": {},
   "source": [
    "To colour by binary ligand-binding label:\n",
    "\n",
    "    color byattribute r:ligand_binding #!1 target scab palette 0,white:0.5,white:1,red"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pymol_env]",
   "language": "python",
   "name": "conda-env-pymol_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
